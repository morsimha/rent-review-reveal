import React, { useState, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { useTheme } from '@/contexts/ThemeContext';
import { useIsMobile } from '@/hooks/use-mobile';
import { ChevronLeft, ChevronRight, Mic, Square, Send, Piano, Play } from 'lucide-react';
import { useToast } from '@/hooks/use-toast';
import { supabase } from '@/integrations/supabase/client';
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";

interface RecordedNote {
  note: string;
  frequency: number;
  timestamp: number;
}

type SoundType = 'sine' | 'square' | 'sawtooth' | 'triangle';

interface AdvancedPianoProps {
  onMelodyAnalysis?: (analysis: string) => void;
}

const AdvancedPiano: React.FC<AdvancedPianoProps> = ({ onMelodyAnalysis }) => {
  const { themeConfig } = useTheme();
  const { toast } = useToast();
  const isMobile = useIsMobile();
  const [octave, setOctave] = useState(4);
  const [isRecording, setIsRecording] = useState(false);
  const [isVoiceRecording, setIsVoiceRecording] = useState(false);
  const [recordedNotes, setRecordedNotes] = useState<RecordedNote[]>([]);
  const [hasVoiceRecording, setHasVoiceRecording] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [soundType, setSoundType] = useState<SoundType>('sine');
  const recordingStartTime = useRef<number>(0);
  const mediaRecorder = useRef<MediaRecorder | null>(null);
  const audioChunks = useRef<Blob[]>([]);
  const voiceRecordingData = useRef<Blob | null>(null);

  // ×ª×•×•×™× ×¤×©×•×˜×™× - ×¨×§ ×”×œ×‘× ×™×
  const notes = [
    { name: '×“×•', baseFreq: 261.63, emoji: 'ğŸµ' },
    { name: '×¨×”', baseFreq: 293.66, emoji: 'ğŸ¶' },
    { name: '××™', baseFreq: 329.63, emoji: 'ğŸ¼' },
    { name: '×¤×”', baseFreq: 349.23, emoji: 'ğŸ¤' },
    { name: '×¡×•×œ', baseFreq: 392.00, emoji: 'ğŸ§' },
    { name: '×œ×”', baseFreq: 440.00, emoji: 'ğŸ¸' },
    { name: '×¡×™', baseFreq: 493.88, emoji: 'ğŸº' },
    { name: '×“×•', baseFreq: 523.25, emoji: 'ğŸ¹' }
  ];

  const soundTypes = [
    { value: 'sine', label: '×¤×¡× ×ª×¨ ×§×œ××¡×™', emoji: 'ğŸ¹' },
    { value: 'square', label: '×¡×™× ×ª×™×¡×™×™×–×¨', emoji: 'ğŸ›ï¸' },
    { value: 'sawtooth', label: '×›×™× ×•×¨ ×—×©××œ×™', emoji: 'ğŸ»' },
    { value: 'triangle', label: '×—×œ×™×œ', emoji: 'ğŸº' }
  ];

  // ×—×™×©×•×‘ ×ª×“×¨ ×œ×¤×™ ××•×§×˜×‘×”
  const getFrequency = (baseFreq: number, octave: number) => {
    return baseFreq * Math.pow(2, octave - 4);
  };

  const playNote = (baseFreq: number, noteName: string) => {
    const frequency = getFrequency(baseFreq, octave);
    
    // ×”×§×œ×˜×ª ×”×ª×• ×× ×‘××¦×‘ ×”×§×œ×˜×”
    if (isRecording) {
      const timestamp = Date.now() - recordingStartTime.current;
      setRecordedNotes(prev => [...prev, { note: `${noteName}${octave}`, frequency, timestamp }]);
    }

    try {
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const oscillator = audioContext.createOscillator();
      const gainNode = audioContext.createGain();
      
      oscillator.connect(gainNode);
      gainNode.connect(audioContext.destination);
      
      oscillator.frequency.setValueAtTime(frequency, audioContext.currentTime);
      oscillator.type = soundType;
      
      gainNode.gain.setValueAtTime(0.4, audioContext.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 1.2);
      
      oscillator.start();
      oscillator.stop(audioContext.currentTime + 1.2);
      
      setTimeout(() => {
        audioContext.close();
      }, 1300);
    } catch (error) {
      console.log('Failed to play note:', error);
    }
  };

  const startPianoRecording = () => {
    setIsRecording(true);
    setRecordedNotes([]);
    recordingStartTime.current = Date.now();
    toast({
      title: "×”×ª×—×œ×ª ×”×§×œ×˜×ª ×¤×¡× ×ª×¨ ğŸ¹",
      description: "× ×’×Ÿ ××ª ×”×× ×’×™× ×” ×©×œ×š!",
    });
  };

  const stopPianoRecording = () => {
    setIsRecording(false);
    toast({
      title: "×”×§×œ×˜×ª ×¤×¡× ×ª×¨ ×”×¡×ª×™×™××”",
      description: `×”×•×§×œ×˜×• ${recordedNotes.length} ×ª×•×•×™×`,
    });
  };

  const startVoiceRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder.current = new MediaRecorder(stream);
      audioChunks.current = [];

      mediaRecorder.current.ondataavailable = (event) => {
        audioChunks.current.push(event.data);
      };

      mediaRecorder.current.onstop = async () => {
        const audioBlob = new Blob(audioChunks.current, { type: 'audio/wav' });
        voiceRecordingData.current = audioBlob;
        setHasVoiceRecording(true);
      };

      mediaRecorder.current.start();
      setIsVoiceRecording(true);
      
      toast({
        title: "×”×ª×—×œ×ª ×”×§×œ×˜×ª ×§×•×œ ğŸ¤",
        description: "×©×™×¨ ××• × ×©×¨×•×§ ××ª ×”×× ×’×™× ×”!",
      });
    } catch (error) {
      toast({
        title: "×©×’×™××”",
        description: "×œ× ×”×¦×œ×—× ×• ×œ×’×©×ª ×œ××™×§×¨×•×¤×•×Ÿ",
        variant: "destructive"
      });
    }
  };

  const stopVoiceRecording = () => {
    if (mediaRecorder.current && isVoiceRecording) {
      mediaRecorder.current.stop();
      mediaRecorder.current.stream.getTracks().forEach(track => track.stop());
      setIsVoiceRecording(false);
      
      toast({
        title: "×”×§×œ×˜×ª ×§×•×œ ×”×¡×ª×™×™××”",
        description: "×”×”×§×œ×˜×” ××•×›× ×” ×œ× ×™×ª×•×—!",
      });
    }
  };

  const analyzeMelody = async () => {
    if (recordedNotes.length === 0 && !hasVoiceRecording) {
      toast({
        title: "××™×Ÿ ×× ×’×™× ×”",
        description: "×§×•×“× ×”×§×œ×˜ ×× ×’×™× ×” ×‘×¤×¡× ×ª×¨ ××• ×‘×§×•×œ!",
        variant: "destructive"
      });
      return;
    }

    setIsAnalyzing(true);
    
    try {
      let result;
      
      if (hasVoiceRecording && voiceRecordingData.current) {
        // × ×™×ª×•×— ×”×§×œ×˜×ª ×§×•×œ
        const reader = new FileReader();
        reader.onloadend = async () => {
          const base64Audio = (reader.result as string).split(',')[1];
          
          const { data, error } = await supabase.functions.invoke('analyze-melody', {
            body: { 
              audioData: base64Audio,
              prompt: "× × ×œ× ×ª×— ××ª ×”×× ×’×™× ×” ×©× ×©×¨×§×” ××• × ×•×©×¨×”. ×–×”×” ××ª ×”×ª×•×•×™× ×•×”×× ×’×™× ×” ×× ×”×™× ××•×›×¨×ª."
            }
          });

          if (error) throw error;
          
          const analysis = data.analysis || "×œ× ×”×¦×œ×—× ×• ×œ×–×”×•×ª ××ª ×”×× ×’×™× ×”";
          if (onMelodyAnalysis) {
            onMelodyAnalysis(analysis);
          }
          
          toast({
            title: "× ×™×ª×•×— ×”×§×œ×˜×ª ×§×•×œ ×”×•×©×œ×",
            description: "×”×ª×•×¦××” ××•×¦×’×ª ×œ××¢×œ×”!",
          });
        };
        reader.readAsDataURL(voiceRecordingData.current);
      } else {
        // × ×™×ª×•×— ×”×§×œ×˜×ª ×¤×¡× ×ª×¨
        const melodyData = recordedNotes.map(note => ({
          note: note.note,
          time: note.timestamp / 1000
        }));

        const prompt = `× × ×œ× ×ª×— ××ª ×”×× ×’×™× ×” ×”×‘××” ×©× ×•×’× ×” ×‘×¤×¡× ×ª×¨:
${melodyData.map(n => `${n.note} ×‘×–××Ÿ ${n.time.toFixed(2)}s`).join(', ')}

×”×× ×–×• ×× ×’×™× ×” ××•×›×¨×ª? ×× ×›×Ÿ, ××” ×©××”? ×ª×Ÿ × ×™×ª×•×— ×§×¦×¨ ×©×œ ×”×× ×’×™× ×”.`;

        const { data, error } = await supabase.functions.invoke('analyze-melody', {
          body: { 
            melody: melodyData,
            prompt: prompt 
          }
        });

        if (error) throw error;

        const analysis = data.analysis || "×œ× ×”×¦×œ×—× ×• ×œ×–×”×•×ª ××ª ×”×× ×’×™× ×”";
        if (onMelodyAnalysis) {
          onMelodyAnalysis(analysis);
        }
        
        toast({
          title: "× ×™×ª×•×— ×”×× ×’×™× ×” ×”×•×©×œ×",
          description: "×”×ª×•×¦××” ××•×¦×’×ª ×œ××¢×œ×”!",
        });
      }
    } catch (error) {
      console.error('Error analyzing melody:', error);
      toast({
        title: "×©×’×™××”",
        description: "×œ× ×”×¦×œ×—× ×• ×œ× ×ª×— ××ª ×”×× ×’×™× ×”",
        variant: "destructive"
      });
    } finally {
      setIsAnalyzing(false);
    }
  };

  // responsive styles
  const getButtonSize = () => isMobile ? "text-lg px-2 py-3 min-w-8 min-h-10" : "text-2xl px-4 py-2 min-w-12 min-h-12";
  const getControlSize = () => isMobile ? "text-xs px-2 py-1" : "text-sm px-3 py-2";

  return (
    <div className="flex flex-col items-center gap-4 p-4 max-w-full overflow-hidden">
      {/* ×‘×§×¨×•×ª ××•×§×˜×‘×” ×•×¡×•×’ ×¦×œ×™×œ */}
      <div className="flex flex-col items-center gap-3 w-full">
        <div className="flex items-center gap-2">
          <Button
            onClick={() => setOctave(Math.max(1, octave - 1))}
            disabled={octave <= 1}
            size="sm"
            variant="outline"
            className={`h-8 ${isMobile ? 'px-2' : 'px-3'}`}
          >
            <ChevronLeft className="w-4 h-4" />
          </Button>
          
          <span className={`font-medium ${isMobile ? 'text-xs px-2' : 'text-sm px-3'}`}>
