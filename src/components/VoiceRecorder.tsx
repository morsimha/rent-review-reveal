import React, { useState, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { Mic, Square, Send, Music2, Sparkles } from 'lucide-react';
import { useToast } from '@/hooks/use-toast';
import { supabase } from '@/integrations/supabase/client';

const VoiceRecorder: React.FC = () => {
  const { toast } = useToast();
  const [isRecording, setIsRecording] = useState(false);
  const [hasRecording, setHasRecording] = useState(false);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [volumeLevel, setVolumeLevel] = useState(0); // ×¨××ª ×¢×•×¦××” ×‘×–××Ÿ ×××ª
  const [analysisResult, setAnalysisResult] = useState<string | null>(null); // ×ª×•×¦××ª ×”× ×™×ª×•×— ×œ×ª×¦×•×’×”
  
  const mediaRecorder = useRef<MediaRecorder | null>(null);
  const audioChunks = useRef<Blob[]>([]);
  const audioBlob = useRef<Blob | null>(null);
  const timerInterval = useRef<NodeJS.Timeout | null>(null);

  // ×¤×•× ×§×¦×™×” ×œ× ×™×˜×•×¨ ×¢×•×¦××” ×‘×–××Ÿ ×××ª
  const monitorVolume = (stream: MediaStream) => {
    const audioContext = new AudioContext();
    const analyser = audioContext.createAnalyser();
    const microphone = audioContext.createMediaStreamSource(stream);
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    
    microphone.connect(analyser);
    analyser.fftSize = 256;
    
    const updateVolume = () => {
      if (!isRecording) return;
      
      analyser.getByteFrequencyData(dataArray);
      const average = dataArray.reduce((sum, value) => sum + value) / dataArray.length;
      const normalizedVolume = Math.min(average / 128, 1); // × ×¨××•×œ ×‘×™×Ÿ 0-1
      
      setVolumeLevel(normalizedVolume);
      
      if (isRecording) {
        requestAnimationFrame(updateVolume);
      }
    };
    
    updateVolume();
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder.current = new MediaRecorder(stream);
      audioChunks.current = [];
      setRecordingDuration(0);
      setVolumeLevel(0);
      setAnalysisResult(null); // ××™×¤×•×¡ ×ª×•×¦××” ×§×•×“××ª

      // ×”×ª×—×œ × ×™×˜×•×¨ ×¢×•×¦××”
      monitorVolume(stream);

      // Start timer
      timerInterval.current = setInterval(() => {
        setRecordingDuration(prev => prev + 1);
      }, 1000);

      mediaRecorder.current.ondataavailable = (event) => {
        audioChunks.current.push(event.data);
      };

      mediaRecorder.current.onstop = async () => {
        if (timerInterval.current) {
          clearInterval(timerInterval.current);
        }
        
        audioBlob.current = new Blob(audioChunks.current, { type: 'audio/webm' });
        setHasRecording(true);
        setVolumeLevel(0); // ××™×¤×•×¡ ×¨××ª ×”×¢×•×¦××”
        
        // Stop all tracks
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.current.start();
      setIsRecording(true);
      
      toast({
        title: "ğŸ¤ ×”×§×œ×˜×” ×”×ª×—×™×œ×”!",
        description: "×©×™×¨, ×©×¨×•×§, ××• ×–××–× ××ª ×”×× ×’×™× ×” ×©×œ×š",
      });
    } catch (error) {
      toast({
        title: "××•×¤×¡! ğŸ˜…",
        description: "× ×¨××” ×©×”××™×§×¨×•×¤×•×Ÿ ×©×œ×š ×‘×™×™×©×Ÿ. ×‘×“×•×§ ××ª ×”×”×¨×©××•×ª!",
        variant: "destructive"
      });
    }
  };

  const stopRecording = () => {
    if (mediaRecorder.current && isRecording) {
      mediaRecorder.current.stop();
      setIsRecording(false);
      
      toast({
        title: "ğŸµ ×”×§×œ×˜×” × ×©××¨×”!",
        description: `${recordingDuration} ×©× ×™×•×ª ×©×œ ×§×¡× ××•×–×™×§×œ×™`,
      });
    }
  };

  // × ×™×ª×•×— ×‘×¡×™×¡×™ ×©×œ ×”×”×§×œ×˜×”
  const analyzeAudioBasic = async (audioBlob: Blob, duration: number): Promise<string> => {
    try {
      // × ×™×ª×•×— ×‘×¡×™×¡×™ ×©×œ ×”×§×•×œ
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const arrayBuffer = await audioBlob.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      // ×—×™×©×•×‘ ×¢×•×¦××” ×××•×¦×¢×ª
      const channelData = audioBuffer.getChannelData(0);
      const avgVolume = channelData.reduce((sum, sample) => sum + Math.abs(sample), 0) / channelData.length;
      
      // ×—×™×©×•×‘ ×©×™× ×•×™×™× ×‘×¢×•×¦××” (×“×™× ××™×§×”)
      let volumeChanges = 0;
      let prevVolume = Math.abs(channelData[0]);
      for (let i = 1000; i < channelData.length; i += 1000) {
        const currentVolume = Math.abs(channelData[i]);
        if (Math.abs(currentVolume - prevVolume) > 0.01) {
          volumeChanges++;
        }
        prevVolume = currentVolume;
      }
      
      // × ×™×ª×•×— ×××¤×™×™× ×™×
      const isDynamic = volumeChanges > duration * 2; // ×”×¨×‘×” ×©×™× ×•×™×™×
      const isLoud = avgVolume > 0.1;
      const isSoft = avgVolume < 0.03;
      const isLong = duration > 8;
      const isShort = duration < 3;
      
      // ×™×¦×™×¨×ª ×ª×™××•×¨ ×—×›×
      return generateSmartDescription(duration, isLoud, isSoft, isDynamic, isLong, isShort);
      
    } catch (error) {
      // ×× ×”× ×™×ª×•×— × ×›×©×œ, ×ª×—×–×•×¨ ×œ×ª×™××•×¨ ×‘×¡×™×¡×™
      return generateBasicDescription(duration);
    }
  };

  // ×™×¦×™×¨×ª ×ª×™××•×¨ ×—×›×
  const generateSmartDescription = (
    duration: number, 
    isLoud: boolean, 
    isSoft: boolean, 
    isDynamic: boolean, 
    isLong: boolean, 
    isShort: boolean
  ): string => {
    
    const personalityTypes = [
      {
        condition: isLoud && isDynamic,
        responses: [
          "ğŸ”¥ ×•×•××•! ×–×” × ×©××¢ ×›××• ×× ×¨×’×™×” ×˜×”×•×¨×”! ×”×× ×–×” ×”×™×” ×¨×•×§ ××• ×©××ª×” ×¤×©×•×˜ × ××¦× ×‘××¦×‘ ×¨×•×— ××¢×•×œ×”?",
          "âš¡ ××™×–×” ×›×•×—! ×”×”×§×œ×˜×” ×©×œ×š ××œ××” ×‘×× ×¨×’×™×” - × ×©××¢ ×›××• ×©×™×¨ ×× ×¦×—!",
          "ğŸ¸ ×”×¨×’×©×ª×™ ××ª ×”×¨×¢×™×“×•×ª ×¢×“ ×›××Ÿ! ×–×” ×‘×”×—×œ×˜ ×œ× ×©×™×¨ ×¢×¨×©..."
        ]
      },
      {
        condition: isSoft && !isDynamic,
        responses: [
          "ğŸŒ™ ×××© ×™×¤×” ×•×¢×“×™×Ÿ... ×–×” ×”×™×” ×©×™×¨ ×¢×¨×© ××• ×©××ª×” ×‘××•×“ ×¨×•×× ×˜×™?",
          "ğŸ•Šï¸ ××™×–×” ×¢×“×™× ×•×ª! ×”×”×§×œ×˜×” ×©×œ×š × ×©××¢×ª ×›××• ××œ××š ×©×œ×•×—×© ×¡×•×“×•×ª",
          "ğŸŒ¸ ×××© ××¨×’×™×¢ ×•× ×¢×™× - ×‘×“×™×•×§ ××” ×©×”×œ×‘ ×¦×¨×™×š!"
        ]
      },
      {
        condition: isDynamic && !isLoud,
        responses: [
          "ğŸ­ ×™×© ×›××Ÿ ×”×¨×‘×” ×¨×’×©! ×”×¨×’×©×ª×™ ×¢×œ×™×•×ª ×•×™×¨×™×“×•×ª - ×–×” × ×©××¢ ×›××• ×¡×™×¤×•×¨ ××•×–×™×§×œ×™",
          "ğŸŒŠ ×›××• ×’×œ×™× ×‘×™×! ×”×”×§×œ×˜×” ×©×œ×š ××œ××” ×‘×“×™× ××™×§×” ××¢× ×™×™× ×ª",
          "ğŸ¢ ××™×–×” ××¡×¢ ×¨×’×©×™! ××”×©×§×˜ ×œ×—×–×§ ×•×‘×—×–×¨×” - ×××Ÿ ×××™×ª×™!"
        ]
      },
      {
        condition: isShort,
        responses: [
          "âš¡ ×§×¦×¨ ×•×—×“ - ×›××• ×”×§×¦×‘ ×©×œ ××™× ×¡×˜×’×¨×! ×œ×¤×¢××™× ×¤×—×•×ª ×–×” ×™×•×ª×¨",
          "ğŸ’ ×™×¦×™×¨×” ××™× ×™ ××‘×œ ×¢× ×”×©×¤×¢×” ××§×¡×™××œ×™×ª!",
          "ğŸ¯ ×™×©×¨ ×œ×¢× ×™×™×Ÿ - ××”×‘×ª×™ ××ª ×”×‘×™×˜×—×•×Ÿ!"
        ]
      },
      {
        condition: isLong,
        responses: [
          `ğŸƒâ€â™‚ï¸ ××™×–×” ×¡×‘×œ× ×•×ª ××•×–×™×§×œ×™×ª! ${Math.floor(duration)} ×©× ×™×•×ª ×©×œ ×™×¦×™×¨×” ×¨×¦×•×¤×”`,
          "ğŸ¼ ××•×¤×¨×” ××™×©×™×ª! ×”×”×§×œ×˜×” ×”××¨×•×›×” ×©×œ×š ××¨××” ××—×•×™×‘×•×ª ×××™×ª×™×ª ×œ××× ×•×ª",
          `â° ${Math.floor(duration)} ×©× ×™×•×ª ×©×œ ×§×¡× ×˜×”×•×¨ - ×–×” ×›×‘×¨ ×›××¢×˜ ×©×™×¨ ×©×œ×!`
        ]
      }
    ];
    
    // ××¦× ××ª ×”×¡×•×’ ×”×¨××©×•×Ÿ ×©××ª××™×
    for (const type of personalityTypes) {
      if (type.condition) {
        return type.responses[Math.floor(Math.random() * type.responses.length)];
      }
    }
    
    // ×‘×¨×™×¨×ª ××—×“×œ
    return generateBasicDescription(duration);
  };

  // ×ª×™××•×¨ ×‘×¡×™×¡×™ (×›-fallback)
  const generateBasicDescription = (duration: number): string => {
    const basicResponses = [
      `ğŸµ ×”×§×œ×˜×ª ${Math.floor(duration)} ×©× ×™×•×ª ×©×œ ××•×–×™×§×”! × ×©××¢ ×›××•... ××©×”×• ××§×¡×™×!`,
      "ğŸ¤ AI ×©×œ× ×• ××•××¨: ×–×” ×‘×”×—×œ×˜ ×§×•×œ ×× ×•×©×™ ×•×‘×”×—×œ×˜ ××•×–×™×§×œ×™!",
      "ğŸ¤– ×”× ×™×ª×•×— ×©×œ× ×• ××¨××”: 100% ××•×–×™×§×”, 0% ×©×§×˜, ×•-âˆ ×›×™×©×¨×•×Ÿ!",
      "ğŸ­ ×œ×¤×™ ×”××—×©×‘ ×©×œ× ×• - ×™×© ×›××Ÿ ×¨×’×©×•×ª, ×× ×’×™× ×”, ×•×”×¨×‘×” ××”×‘×”!",
      "ğŸŒŸ ×”×§×•×œ ×©×œ×š ×¢×‘×¨ ××ª ××‘×—×Ÿ ×”××™×›×•×ª ×©×œ× ×• ×‘×”×¦×œ×—×” ××¨×©×™××”!"
    ];
    
    return basicResponses[Math.floor(Math.random() * basicResponses.length)];
  };

  const analyzeRecording = async () => {
    if (!audioBlob.current) {
      toast({
        title: "×¨×’×¢, ××”? ğŸ¤”",
        description: "××™×Ÿ ×”×§×œ×˜×”! ×ª× ×¡×” ×œ×”×§×œ×™×˜ ××©×”×• ×§×•×“×",
        variant: "destructive"
      });
      return;
    }

    setIsAnalyzing(true);
    setAnalysisResult(null); // ××™×¤×•×¡ ×ª×•×¦××” ×§×•×“××ª
    
    try {
      // × ×™×ª×•×— ×‘×¡×™×¡×™ ×©×œ ×”×”×§×œ×˜×”
      const analysis = await analyzeAudioBasic(audioBlob.current, recordingDuration);
      
      setAnalysisResult(analysis); // ×©××™×¨×ª ×”×ª×•×¦××” ×œ×”×¦×’×”
      
      toast({
        title: "ğŸ­ ×”× ×™×ª×•×— ×”×¡×ª×™×™×!",
        description: "×’×œ×•×œ ×œ××˜×” ×œ×¨××•×ª ××ª ×”×ª×•×¦××•×ª ×”××œ××•×ª",
        duration: 5000
      });
    } catch (error) {
      console.error('Error analyzing voice:', error);
      setAnalysisResult("××•×¤×¡! ××©×”×• ×”×©×ª×‘×© ×‘× ×™×ª×•×—. × ×¡×” ×©×•×‘! ğŸ¤–");
      
      toast({
        title: "×©×’×™××” ×‘× ×™×ª×•×— ğŸ¤–",
        description: "× ×¨××” ×©×”-AI ×©×œ× ×• ×™×¦× ×œ×”×¤×¡×§×ª ×§×¤×”. × ×¡×” ×©×•×‘!",
        variant: "destructive"
      });
    } finally {
      setIsAnalyzing(false);
    }
  };

  // ××™×¤×•×¡ ×”×§×œ×˜×”
  const resetRecording = () => {
    setHasRecording(false);
    setAnalysisResult(null);
    setRecordingDuration(0);
    setVolumeLevel(0);
    audioBlob.current = null;
    
    toast({
      title: "ğŸ”„ ××™×¤×•×¡ ×”×•×©×œ×",
      description: "××•×›×Ÿ ×œ×”×§×œ×˜×” ×—×“×©×”!",
    });
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="flex flex-col items-center gap-6 p-8 max-w-md mx-auto">
      {/* ×›×•×ª×¨×ª ××¦×—×™×§×” */}
      <div className="text-center space-y-2">
        <h3 className="text-2xl font-bold bg-gradient-to-r from-purple-600 to-pink-600 bg-clip-text text-transparent">
          ğŸ¤ ××•×œ×¤×Ÿ ×”×–××¨×” ×”×‘×™×ª×™ ğŸ¤
        </h3>
        <p className="text-gray-600 text-sm">
          ×©×™×¨, ×©×¨×•×§, ×–××–×, ××• ×¤×©×•×˜ ×ª×¢×©×” ×§×•×œ×•×ª ××•×–×¨×™×!
        </p>
      </div>

      {/* ×•×™×–×•××œ×™×–×¦×™×” ××©×•×¤×¨×ª ×©×œ ×”×§×œ×˜×” */}
      <div className="relative">
        <div className={`w-32 h-32 rounded-full flex items-center justify-center transition-all duration-300 ${
          isRecording 
            ? 'bg-gradient-to-r from-red-400 to-pink-400 shadow-lg shadow-red-300' 
            : hasRecording
            ? 'bg-gradient-to-r from-green-400 to-emerald-400 shadow-lg shadow-green-300'
            : 'bg-gradient-to-r from-gray-200 to-gray-300'
        }`}
        style={{
          transform: isRecording ? `scale(${1 + volumeLevel * 0.3})` : 'scale(1)',
          boxShadow: isRecording 
            ? `0 0 ${20 + volumeLevel * 30}px rgba(239, 68, 68, ${0.3 + volumeLevel * 0.4})`
            : hasRecording 
            ? '0 0 20px rgba(34, 197, 94, 0.3)'
            : 'none'
        }}>
          <Mic className={`w-16 h-16 text-white ${isRecording ? 'animate-pulse' : ''}`} />
        </div>
        
        {/* ×× ×™××¦×™×” ×©×œ ×’×œ×™ ×§×•×œ */}
        {isRecording && (
          <>
            {[1, 2, 3].map((ring) => (
              <div
                key={ring}
                className="absolute rounded-full border-2 border-red-300 animate-ping"
                style={{
                  width: `${132 + ring * 20 + volumeLevel * 40}px`,
                  height: `${132 + ring * 20 + volumeLevel * 40}px`,
                  top: '50%',
                  left: '50%',
                  transform: 'translate(-50%, -50%)',
                  animationDelay: `${ring * 0.2}s`,
                  opacity: Math.max(0.1, volumeLevel - ring * 0.2)
                }}
              />
            ))}
          </>
        )}
        
        {/* ×˜×™×™××¨ */}
        {isRecording && (
          <div className="absolute -bottom-8 left-1/2 transform -translate-x-1/2">
            <span className="text-2xl font-mono font-bold text-red-500 animate-pulse">
              {formatTime(recordingDuration)}
            </span>
          </div>
        )}
        
        {/* ××“ ×¢×•×¦××” */}
        {isRecording && (
          <div className="absolute -right-16 top-1/2 transform -translate-y-1/2">
            <div className="w-3 h-24 bg-gray-200 rounded-full overflow-hidden">
              <div 
                className="w-full bg-gradient-to-t from-green-400 via-yellow-400 to-red-400 transition-all duration-100 rounded-full"
                style={{ 
                  height: `${volumeLevel * 100}%`,
                  marginTop: `${(1 - volumeLevel) * 100}%`
                }}
              />
            </div>
            <div className="text-xs text-center mt-1 text-gray-600">×¢×•×¦××”</div>
          </div>
        )}
      </div>

      {/* ×›×¤×ª×•×¨×™ ×¤×¢×•×œ×” */}
      <div className="flex flex-col gap-4 w-full mt-4">
        {!isRecording ? (
          <Button
            onClick={startRecording}
            className="bg-gradient-to-r from-purple-500 to-pink-500 hover:from-purple-600 hover:to-pink-600 text-white py-6 text-lg rounded-full shadow-lg transform transition-all duration-200 hover:scale-105"
          >
            <Mic className="w-6 h-6 mr-2" />
            ×”×ª×—×œ ×”×§×œ×˜×”
          </Button>
        ) : (
          <Button
            onClick={stopRecording}
            className="bg-gradient-to-r from-red-500 to-red-600 hover:from-red-600 hover:to-red-700 text-white py-6 text-lg rounded-full shadow-lg animate-pulse"
          >
            <Square className="w-6 h-6 mr-2" />
            ×¢×¦×•×¨ ×”×§×œ×˜×”
          </Button>
        )}
        
        {hasRecording && !isRecording && (
          <div className="flex gap-3 w-full">
            <Button
              onClick={analyzeRecording}
              disabled={isAnalyzing}
              className="bg-gradient-to-r from-green-500 to-emerald-500 hover:from-green-600 hover:to-emerald-600 text-white py-6 text-lg rounded-full shadow-lg transform transition-all duration-200 hover:scale-105 flex-1"
            >
              {isAnalyzing ? (
                <>
                  <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-white mr-2" />
                  ×× ×ª×— ××ª ×”×™×¦×™×¨×”...
                </>
              ) : (
                <>
                  <Sparkles className="w-6 h-6 mr-2" />
                  ×‘×•× × ×¨××” ××” ×”×§×œ×˜×ª!
                </>
              )}
            </Button>
            
            <Button
              onClick={resetRecording}
              className="bg-gradient-to-r from-gray-400 to-gray-500 hover:from-gray-500 hover:to-gray-600 text-white py-6 px-4 rounded-full shadow-lg transform transition-all duration-200 hover:scale-105"
              title="×”×ª×—×œ ××—×“×©"
            >
              ğŸ”„
            </Button>
          </div>
        )}
      </div>

      {/* ×ª×•×¦××•×ª × ×™×ª×•×— */}
      {analysisResult && !isAnalyzing && (
        <div className="bg-gradient-to-r from-purple-50 to-pink-50 rounded-2xl p-6 mt-6 border-2 border-purple-200 max-w-md">
          <div className="text-center">
            <div className="text-2xl mb-3">ğŸ­</div>
            <h4 className="font-bold text-purple-800 mb-3">×ª×•×¦××•×ª ×”× ×™×ª×•×—</h4>
            <p className="text-purple-700 leading-relaxed">
              {analysisResult}
            </p>
            <div className="flex justify-center gap-2 mt-4">
              {['ğŸµ', 'ğŸ¶', 'ğŸ¼', 'ğŸ¤', 'ğŸ¸'].map((emoji, i) => (
                <span
                  key={i}
                  className="text-lg animate-bounce"
                  style={{ animationDelay: `${i * 0.1}s` }}
                >
                  {emoji}
                </span>
              ))}
            </div>
          </div>
        </div>
      )}

      {/* ×˜×™×¤×™× ××¦×—×™×§×™× */}
      <div className="bg-purple-50 rounded-2xl p-4 mt-4 border-2 border-purple-200">
        <p className="text-center text-sm text-purple-700 font-medium">
          ğŸ’¡ ×˜×™×¤: ××¤×©×¨ ×’× ×œ×©×¨×•×§ ×›××• ×¦×™×¤×•×¨, ×œ×–××–× ×›××• ×“×‘×•×¨×”, ××• ×¤×©×•×˜ ×œ×”×’×™×“ "×œ×” ×œ×” ×œ×”" ×‘×§×¦×‘!
        </p>
      </div>

      {/* ×× ×™××¦×™×” ××¦×—×™×§×” */}
      {isRecording && (
        <div className="flex gap-2 mt-4">
          {['ğŸµ', 'ğŸ¶', 'ğŸ¼', 'ğŸ¤', 'ğŸ¸'].map((emoji, i) => (
            <span
              key={i}
              className="text-2xl animate-bounce"
              style={{ animationDelay: `${i * 0.1}s` }}
            >
              {emoji}
            </span>
          ))}
        </div>
      )}
    </div>
  );
};

export default VoiceRecorder;